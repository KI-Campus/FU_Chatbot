================================================================================
DOCUMENT TEXT
================================================================================

Module Name: Folien

--- Dokument (EinfÃ¼hrung Deep Learning.zip) ---
ZIP-Archiv: EinfÃ¼hrung Deep Learning.zip

--- PDF: DLfsP_M1_Einf_hrungDL.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
Modul 1 â€“ EinfÃ¼hrung Deep Learning

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 2
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung Neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 3
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ KÃ¼nstliche Intelligenz
â€¢ Maschinelles Lernen
â€¢ Deep Learning
â€¢ Wiederholung Neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 4 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 4
EinfÃ¼hrung Deep Learning
Definition â€“ KÃ¼nstliche Intelligenz
KÃ¼nstliche Intelligenz (KI) ist ein Teilgebiet der Informatik. Sie erforscht Mechanismen, die intelligentes
menschliches Verhalten simulieren kÃ¶nnen. Das beinhaltet zum Beispiel, eigenstÃ¤ndig Schlussfolgerungen zu
ziehen, angemessen auf Situationen zu reagieren oder aus Erfahrungen zu lernen. (Definition BMBF, Sachstand
kÃ¼nstliche Intelligenz 2019, Link)
KÃ¼nstliche Intelligenz
Maschinelles Lernen

--- Page 5 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 5
EinfÃ¼hrung Deep Learning
Definition â€“ Maschinelles Lernen
Maschinen lernen, indem sie aus vorliegenden Beispieldaten Muster erkennen, daraus Modelle entwickeln und
dieses Wissen auf neue, ihnen bisher unbekannte Situationen anwenden. Je grÃ¶ÃŸer und aussagekrÃ¤ftiger die
Datenmenge, desto besser lernen sie. (BMBF - KÃ¼nstliche Intelligenz - #ChanceKI, MÃ¤rz 2020)
KÃ¼nstliche Intelligenz
Maschinelles Lernen
Deep Learning

--- Page 6 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 6
EinfÃ¼hrung Deep Learning
Definition â€“ Deep Learning
Maschinelles Lernen mit groÃŸen KNN wird als Deep Learning bezeichnet. Je komplexer das KNN, desto hÃ¶her ist
der mÃ¶gliche Abstraktionsgrad und desto schwierigere Sachverhalte kÃ¶nnen bearbeitet werden. AlltÃ¤gliche
Anwendungsbeispiele sind die Bild- oder Spracherkennung. (BMBF - KÃ¼nstliche Intelligenz - #ChanceKI, MÃ¤rz
2020)
Deep Learning heiÃŸt eigentlich nicht Deep Learning, weil die neuronalen Netze tief, also viele Schichten, haben.
â€œBy gathering knowledge from experience, this approach avoids the need for human operators to formally
specify all the knowledge that the computer needs. The hierarchy of concepts enables the computer to learn
complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are
built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI deep
learning.â€ (I. Goodfellow, Deep Learning)
Ganz knapp gesagt:
Deep Learning lernt Features selbststÃ¤ndig
Machine Learning bekommt Features

--- Page 7 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 7
EinfÃ¼hrung Deep Learning
Definition â€“ Achievements DL
Ãœbersetzungsprogramme
Spracherkennung und â€“Erzeugung
Bild- und Objekterkennung, Erzeugung von Bildern
Autonomes Fahren

--- Page 8 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 8
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung Neuronale Netze
â€¢ Wichtige Begriffe
â€¢ Aktivierungsfunktionen
â€¢ Loss Funktion
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 9 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 9
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ wichtige Begriffe
Input Layer
Hidden Layer
Bias
Gewicht
Aktivierungsfunktion
Loss Funktion
Optimierer
Backpropagation
Input
Layer
Hidden
Layer
ğ‘§ğ‘§1
ğ‘¥ğ‘¥1
ğ‘¥ğ‘¥2
Bias
ğ‘§ğ‘§2
Bias
Output
Layer
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ‘¥ğ‘¥3

--- Page 10 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 10
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Aktivierungsfunktionen
Tangens hyperbolicus (tanh):
ğ‘“ğ‘“ğ‘ğ‘= tanh(ğ‘ğ‘)
â‡’Verwende als Aktivierungsfunktion fÃ¼r Hidden
Layers bei kleinen Netzen
ReLU (Rectified Linear Unit):
ğ‘“ğ‘“ğ‘ğ‘= max(0, ğ‘ğ‘)
â‡’In grÃ¶ÃŸeren Netzen als Aktivierungsfunktion fÃ¼r
Hidden Layers verwenden

--- Page 11 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 11
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Aktivierungsfunktionen
Logistische Sigmoidfunktion:
ğ‘“ğ‘“ğ‘ğ‘=
1 + exp(âˆ’ğ‘ğ‘)
â‡’Verwende bei binÃ¤ren Klassifikationen als
Aktivierungsfunktion fÃ¼r den Outputknoten
Softmax:
ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘=
exp ğ‘¤ğ‘¤ğ‘–ğ‘–â‹…ğ‘§ğ‘§
âˆ‘ğ‘˜ğ‘˜exp ğ‘¤ğ‘¤ğ‘˜ğ‘˜â‹…ğ‘§ğ‘§
Der Wert eines Outputknoten ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘entspricht der
Wahrscheinlichkeit der Klasse ğ‘–ğ‘–anzugehÃ¶ren.
Vorhersage der Klasse mit der hÃ¶chsten
Wahrscheinlichkeit, also
Klasse ğ¶ğ¶ğ‘–ğ‘–, wenn ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘= max
ğ‘¦ğ‘¦ğ‘˜ğ‘˜,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
â‡’Verwende bei Multiclass Klassifikationen als
Aktivierungsfunktion fÃ¼r den Outputknoten

--- Page 12 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 12
Input
Output
ğ‘¥ğ‘¥1
ğ‘¥ğ‘¥2
ğ‘¥ğ‘¥3
Verzerrung
ğ‘¤ğ‘¤1
ğ‘¤ğ‘¤2
ğ‘¤ğ‘¤3
ğ‘¤ğ‘¤0
Loss
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Zielwert
Gewichts-
update
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Loss Funktion
Loss Funktion fÃ¼r Regression:
Mean Squared Error (dt. Quadratischen Abweichung) fÃ¼r
ein Datenpunkt (ğ‘¥ğ‘¥ğ‘–ğ‘–, ğ‘¦ğ‘¦ğ‘–ğ‘–) mit Vorhersage ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ½ğ½ğ‘¤ğ‘¤= 1
2 ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–2
Loss Funktion fÃ¼r Klassifikation:
Categorical Crossentropy (dt. Kreuzentropie) fÃ¼r ein
Datenpunkt (ğ‘¥ğ‘¥ğ‘–ğ‘–, ğ‘¦ğ‘¦ğ‘–ğ‘–) mit Vorhersage ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ½ğ½ğ‘¤ğ‘¤= âˆ’à·
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘–ğ‘–ln ğ‘¦ğ‘¦ğ‘ğ‘,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Binary Crossentropy:
ğ½ğ½ğ‘¤ğ‘¤= âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–ln ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
âˆ’(1 âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–) ln(1 âˆ’ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Optimierer

--- Page 13 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 13
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung Neuronale Netze
â€¢ Frameworks
â€¢ Ãœbersicht
â€¢ Tensorflow vs. PyTorch
â€¢ Installation
â€¢ Tensor

--- Page 14 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 14
EinfÃ¼hrung Deep Learning
Frameworks â€“ Ãœbersicht
TensorFlow
Deep Learning Framework von Google Brain
Open-Source
Nutzung Ã¼ber Programmiersprache Python, andere (C, C++, Java, JavaSript u.a.) mÃ¶glich
PyTorch
Deep Learning Framework v.a. von Facebook's AI Research lab
Open-Source
Nutzung primÃ¤r Ã¼ber Programmiersprache Python, andere (C++ und Java) mÃ¶glich
Keras
High-Level neural network API fÃ¼r Tensorflow, Theano, CNTK
Abstraktionsschicht, die Bedienbarkeit zugrundeliegener Frameworks immens erhÃ¶ht
Open-Source

--- Page 15 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 15
EinfÃ¼hrung Deep Learning
Frameworks â€“ TensorFlow 1.x vs. PyTorch 1.0
Grundbasis beider Systeme Computational Graphs
TensorFlow nutzt statische Computational Graphs
Bessere Geschwindigkeit und Speichernutzung
Einfacher Modelle zu Exportieren und zu Deployen
Programmierung fÃ¼hlt sich an wie andere Sprache
Schwierig zu debuggen
PyTorch nutzt dynamische Computational Graphs
Besseres einfachere debuggen
Intuitivere pythonische Programmierung
Schlechtere Geschwindigkeit und Speichernutzung
Einfaches Netz/Perzeptron:
a = ğ‘¥ğ‘¥â‹…ğ‘¤ğ‘¤
ğ‘§ğ‘§= ğ‘¤ğ‘¤0 + ğ‘ğ‘
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘= ğ‘“ğ‘“(ğ‘§ğ‘§)
ğ¿ğ¿= ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ‘¦ğ‘¦, ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿
ğ‘¤ğ‘¤0
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘

--- Page 16 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 16
EinfÃ¼hrung Deep Learning
Frameworks â€“ TensorFlow 2.x vs. PyTorch 1.6+
TensorFlow fÃ¼hrt mit Eager Execution imperative Programmierung ein
Pytorch hat static Graph Option fÃ¼r bessere Performance eingefÃ¼hrt
Damit unterscheiden sich die Frameworks nicht mehr grundlegend
GrÃ¼nder von PyTorch
https://twitter.com/soumithchintala/status/1263854044289929221

--- Page 17 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 17
TensorFlow vs. PyTorch
Fazit â€“ Unterschiede gering
Framework
Pro
Contra
TensorFlow
Tensorboard
Nutzt standardmÃ¤ÃŸig gesamten
Grafikspeicher (durch wenige
Zeilen dynamisch skalierbar)
Keras
TF Extended (TFX)
TF Lite, TF.js
Code wird standardmÃ¤ÃŸig und automatisch
auf der GPU ausgefÃ¼hrt
PyTorch
Wird aktuell in der Forschung mehr
verwendet
Daten mÃ¼ssen im Code manuell
auf GPU Ã¼bertragen werden
Viele groÃŸe Player nutzen PyTorch
TorchServer
PyTorch mobile, TorchScript

--- Page 18 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 18
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Environment
â€¢ TensorFlow installieren
â€¢ Tensor

--- Page 19 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 19
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Environments (dt. Umgebungen) sind abgetrennte Bereiche mit eigener Python mit eigenen Paketen.
Die Python Version und die Pakete in den Umgebungen kÃ¶nnen sich unterscheiden und beeinflussen sich nicht!
Warum?
Umgebungen von Zielsystemen imitierbar und austestbar!
Zwischen Paketen gibt es AbhÃ¤ngigkeiten, so dass nicht alle Pakete immer miteinander kompatibel sind.

--- Page 20 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 20
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Umgebung erstellen (per Anaconda [Powershell] Prompt bzw. Kommandozeile)
conda create â€“n DLfsP python=3.8
Umgebung erstellen mit Hilfe einer YAML (per Anaconda [Powershell] Prompt bzw. Kommandozeile)
Achtung, wechsle vorher in das entsprechende Verzeichnis!
conda env create -f environment.yml
Umgebung aktivieren
conda activate DLfsP
VerfÃ¼gbare Umgebungen
conda info --envs
Paket (z.B. numpy) in aktiver Umgebung installieren
conda install numpy
Umgebung deaktivieren
conda deactivate
Umgebung lÃ¶schen
conda env remove -n nutzer_projekt
AufrÃ¤umen nicht mehr gebrauchter Pakete
conda clean --all

--- Page 21 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 21
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Weitere notwendige Pakete: (per Anaconda [Powershell] Prompt bzw. Kommandozeile installieren)
conda install numpy
conda install jupyter notebook
conda install pandas
conda install scikit-learn
conda install matplotlib
conda install seaborn

--- Page 22 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 22
EinfÃ¼hrung Deep Learning
Installation â€“ TensorFlow
Keine Nvidia Grafikkarte vorhanden, dann ist nur die CPU Variante mÃ¶glich:
conda install tensorflow
GPU Variante (fÃ¼r Nvidia Grafikkarten)
Version 2.6
conda install tensorflow-gpu=2.6 tensorflow=2.6
Version 2.3
conda install tensorflow-gpu=2.3 tensorflow=2.3=mkl_py38h1fcfbd6_0
VerfÃ¼gbare Tensorflow Versionen
conda search tensorflow
VerfÃ¼gbare Tensorflow-gpu Versionen
conda search tensorflow-gpu
Achtung, im Video wurde noch
TensorFlow 2.5 installiert. Jedoch gibt
es bei dieser Version Probleme mit
RNN Netzen. Aufgrund von
InkompatibiltÃ¤ten mit numpy. Daher
wird empfohlen TensorFlow 2.6 oder
neuer zu installieren!

--- Page 23 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 23
EinfÃ¼hrung Deep Learning
Installation â€“ TensorFlow
Test, ob Python und Tensorflow richtig installiert wurde (Anaconda [Powershell] Prompt bzw. Kommandozeile):
python -c "import tensorflow as tf; print('TF version: ' + tf.__version__); print('Default GPU Device:
{}'.format(tf.config.list_physical_devices('GPU')))"
In einem Jupyter Notebook:
import tensorflow as tf
import sys
print('Python version: ' + sys.version)
print('TF version: ' + tf.__version__)
if tf.test.is_built_with_gpu_support():
if len(tf.config.list_physical_devices('GPU'))==0:
print('Please install GPU version of TF\n' + 'TF is currently using the CPU')
else:
print('Default GPU Device: {}'.format(tf.config.list_physical_devices('GPU')))
else:
print('TF CPU version active')

--- Page 24 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 24
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 25 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 25
EinfÃ¼hrung Deep Learning
Tensor
Im Bereich der KI, ML und DL wird ein Tensor als ein mehrdimensionales Array definiert.
Beispiele:
Skalar (0D Tensor)
Vektor (1D Tensor)
Matrix (2D Tensor)
3D Tensor
Beispiel: Serie von Matrizen, Farbbild
4D Tensor
Beispiel: Serie von Bildern, Video
5D Tensor
Beispiel: Serie von Videos
1,5
(1, 4, 9, 16, 25)

--- Page 26 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 26
EinfÃ¼hrung Deep Learning
Tensor
Umsetzung von Tensoren in Python allgemein:
Numpy Arrays
fÃ¼r die meisten ML Frameworks (sklearn & co) geeignet
mutable (verÃ¤nderbar)
TensorFlow Tensoren
fÃ¼r TensorFlow
immutable (nicht verÃ¤nderbar)

--- PDF: tud2022_DLfsP_M1_2_Definition.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 3
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ KÃ¼nstliche Intelligenz
â€¢ Maschinelles Lernen
â€¢ Deep Learning
â€¢ Wiederholung Neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 4
EinfÃ¼hrung Deep Learning
Definition â€“ KÃ¼nstliche Intelligenz
KÃ¼nstliche Intelligenz (KI) ist ein Teilgebiet der Informatik. Sie erforscht Mechanismen, die intelligentes
menschliches Verhalten simulieren kÃ¶nnen. Das beinhaltet zum Beispiel, eigenstÃ¤ndig Schlussfolgerungen zu
ziehen, angemessen auf Situationen zu reagieren oder aus Erfahrungen zu lernen. (Definition BMBF, Sachstand
kÃ¼nstliche Intelligenz 2019, Link)
KÃ¼nstliche Intelligenz
Maschinelles Lernen

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 5
EinfÃ¼hrung Deep Learning
Definition â€“ Maschinelles Lernen
Maschinen lernen, indem sie aus vorliegenden Beispieldaten Muster erkennen, daraus Modelle entwickeln und
dieses Wissen auf neue, ihnen bisher unbekannte Situationen anwenden. Je grÃ¶ÃŸer und aussagekrÃ¤ftiger die
Datenmenge, desto besser lernen sie. (BMBF - KÃ¼nstliche Intelligenz - #ChanceKI, MÃ¤rz 2020)
KÃ¼nstliche Intelligenz
Maschinelles Lernen
Deep Learning

--- Page 4 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 6
EinfÃ¼hrung Deep Learning
Definition â€“ Deep Learning
Maschinelles Lernen mit groÃŸen KNN wird als Deep Learning bezeichnet. Je komplexer das KNN, desto hÃ¶her ist
der mÃ¶gliche Abstraktionsgrad und desto schwierigere Sachverhalte kÃ¶nnen bearbeitet werden. AlltÃ¤gliche
Anwendungsbeispiele sind die Bild- oder Spracherkennung. (BMBF - KÃ¼nstliche Intelligenz - #ChanceKI, MÃ¤rz
2020)
Deep Learning heiÃŸt eigentlich nicht Deep Learning, weil die neuronalen Netze tief, also viele Schichten, haben.
â€œBy gathering knowledge from experience, this approach avoids the need for human operators to formally
specify all the knowledge that the computer needs. The hierarchy of concepts enables the computer to learn
complicated concepts by building them out of simpler ones. If we draw a graph showing how these concepts are
built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI deep
learning.â€ (I. Goodfellow, Deep Learning)
Ganz knapp gesagt:
Deep Learning lernt Features selbststÃ¤ndig
Machine Learning bekommt Features

--- Page 5 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 7
EinfÃ¼hrung Deep Learning
Definition â€“ Achievements DL
Ãœbersetzungsprogramme
Spracherkennung und â€“Erzeugung
Bild- und Objekterkennung, Erzeugung von Bildern
Autonomes Fahren

--- PDF: tud2022_DLfsP_M1_3_WiederholungNN.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 8
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung Neuronale Netze
â€¢ Wichtige Begriffe
â€¢ Aktivierungsfunktionen
â€¢ Loss Funktion
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 9
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ wichtige Begriffe
Input Layer
Hidden Layer
Bias
Gewicht
Aktivierungsfunktion
Loss Funktion
Optimierer
Backpropagation
Input
Layer
Hidden
Layer
ğ‘§ğ‘§1
ğ‘¥ğ‘¥1
ğ‘¥ğ‘¥2
Bias
ğ‘§ğ‘§2
Bias
Output
Layer
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ‘¥ğ‘¥3

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 10
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Aktivierungsfunktionen
Tangens hyperbolicus (tanh):
ğ‘“ğ‘“ğ‘ğ‘= tanh(ğ‘ğ‘)
â‡’Verwende als Aktivierungsfunktion fÃ¼r Hidden
Layers bei kleinen Netzen
ReLU (Rectified Linear Unit):
ğ‘“ğ‘“ğ‘ğ‘= max(0, ğ‘ğ‘)
â‡’In grÃ¶ÃŸeren Netzen als Aktivierungsfunktion fÃ¼r
Hidden Layers verwenden

--- Page 4 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 11
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Aktivierungsfunktionen
Logistische Sigmoidfunktion:
ğ‘“ğ‘“ğ‘ğ‘=
1 + exp(âˆ’ğ‘ğ‘)
â‡’Verwende bei binÃ¤ren Klassifikationen als
Aktivierungsfunktion fÃ¼r den Outputknoten
Softmax:
ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘=
exp ğ‘¤ğ‘¤ğ‘–ğ‘–â‹…ğ‘§ğ‘§
âˆ‘ğ‘˜ğ‘˜exp ğ‘¤ğ‘¤ğ‘˜ğ‘˜â‹…ğ‘§ğ‘§
Der Wert eines Outputknoten ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘entspricht der
Wahrscheinlichkeit der Klasse ğ‘–ğ‘–anzugehÃ¶ren.
Vorhersage der Klasse mit der hÃ¶chsten
Wahrscheinlichkeit, also
Klasse ğ¶ğ¶ğ‘–ğ‘–, wenn ğ‘¦ğ‘¦ğ‘–ğ‘–,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘= max
ğ‘¦ğ‘¦ğ‘˜ğ‘˜,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
â‡’Verwende bei Multiclass Klassifikationen als
Aktivierungsfunktion fÃ¼r den Outputknoten

--- Page 5 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 12
Input
Output
ğ‘¥ğ‘¥1
ğ‘¥ğ‘¥2
ğ‘¥ğ‘¥3
Verzerrung
ğ‘¤ğ‘¤1
ğ‘¤ğ‘¤2
ğ‘¤ğ‘¤3
ğ‘¤ğ‘¤0
Loss
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Zielwert
Gewichts-
update
EinfÃ¼hrung Deep Learning
Wiederholung Neuronale Netze â€“ Loss Funktion
Loss Funktion fÃ¼r Regression:
Mean Squared Error (dt. Quadratischen Abweichung) fÃ¼r
ein Datenpunkt (ğ‘¥ğ‘¥ğ‘–ğ‘–, ğ‘¦ğ‘¦ğ‘–ğ‘–) mit Vorhersage ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ½ğ½ğ‘¤ğ‘¤= 1
2 ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–2
Loss Funktion fÃ¼r Klassifikation:
Categorical Crossentropy (dt. Kreuzentropie) fÃ¼r ein
Datenpunkt (ğ‘¥ğ‘¥ğ‘–ğ‘–, ğ‘¦ğ‘¦ğ‘–ğ‘–) mit Vorhersage ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ½ğ½ğ‘¤ğ‘¤= âˆ’à·
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘–ğ‘–ln ğ‘¦ğ‘¦ğ‘ğ‘,ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Binary Crossentropy:
ğ½ğ½ğ‘¤ğ‘¤= âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–ln ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
âˆ’(1 âˆ’ğ‘¦ğ‘¦ğ‘–ğ‘–) ln(1 âˆ’ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
Optimierer

--- PDF: tud2022_DLfsP_M1_4_Frameworks.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 13
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung Neuronale Netze
â€¢ Frameworks
â€¢ Ãœbersicht
â€¢ Tensorflow vs. PyTorch
â€¢ Installation
â€¢ Tensor

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 14
EinfÃ¼hrung Deep Learning
Frameworks â€“ Ãœbersicht
TensorFlow
Deep Learning Framework von Google Brain
Open-Source
Nutzung Ã¼ber Programmiersprache Python, andere (C, C++, Java, JavaSript u.a.) mÃ¶glich
PyTorch
Deep Learning Framework v.a. von Facebook's AI Research lab
Open-Source
Nutzung primÃ¤r Ã¼ber Programmiersprache Python, andere (C++ und Java) mÃ¶glich
Keras
High-Level neural network API fÃ¼r Tensorflow, Theano, CNTK
Abstraktionsschicht, die Bedienbarkeit zugrundeliegener Frameworks immens erhÃ¶ht
Open-Source

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 15
EinfÃ¼hrung Deep Learning
Frameworks â€“ TensorFlow 1.x vs. PyTorch 1.0
Grundbasis beider Systeme Computational Graphs
TensorFlow nutzt statische Computational Graphs
Bessere Geschwindigkeit und Speichernutzung
Einfacher Modelle zu Exportieren und zu Deployen
Programmierung fÃ¼hlt sich an wie andere Sprache
Schwierig zu debuggen
PyTorch nutzt dynamische Computational Graphs
Besseres einfachere debuggen
Intuitivere pythonische Programmierung
Schlechtere Geschwindigkeit und Speichernutzung
Einfaches Netz/Perzeptron:
a = ğ‘¥ğ‘¥â‹…ğ‘¤ğ‘¤
ğ‘§ğ‘§= ğ‘¤ğ‘¤0 + ğ‘ğ‘
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘= ğ‘“ğ‘“(ğ‘§ğ‘§)
ğ¿ğ¿= ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ‘¦ğ‘¦, ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿
ğ‘¤ğ‘¤0
ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘

--- Page 4 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 16
EinfÃ¼hrung Deep Learning
Frameworks â€“ TensorFlow 2.x vs. PyTorch 1.6+
TensorFlow fÃ¼hrt mit Eager Execution imperative Programmierung ein
Pytorch hat static Graph Option fÃ¼r bessere Performance eingefÃ¼hrt
Damit unterscheiden sich die Frameworks nicht mehr grundlegend
GrÃ¼nder von PyTorch
https://twitter.com/soumithchintala/status/1263854044289929221

--- Page 5 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 17
TensorFlow vs. PyTorch
Fazit â€“ Unterschiede gering
Framework
Pro
Contra
TensorFlow
Tensorboard
Nutzt standardmÃ¤ÃŸig gesamten
Grafikspeicher (durch wenige
Zeilen dynamisch skalierbar)
Keras
TF Extended (TFX)
TF Lite, TF.js
Code wird standardmÃ¤ÃŸig und automatisch
auf der GPU ausgefÃ¼hrt
PyTorch
Wird aktuell in der Forschung mehr
verwendet
Daten mÃ¼ssen im Code manuell
auf GPU Ã¼bertragen werden
Viele groÃŸe Player nutzen PyTorch
TorchServer
PyTorch mobile, TorchScript

--- PDF: tud2022_DLfsP_M1_5_Installation.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 18
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Environment
â€¢ TensorFlow installieren
â€¢ Tensor

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 19
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Environments (dt. Umgebungen) sind abgetrennte Bereiche mit eigener Python mit eigenen Paketen.
Die Python Version und die Pakete in den Umgebungen kÃ¶nnen sich unterscheiden und beeinflussen sich nicht!
Warum?
Umgebungen von Zielsystemen imitierbar und austestbar!
Zwischen Paketen gibt es AbhÃ¤ngigkeiten, so dass nicht alle Pakete immer miteinander kompatibel sind.

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 20
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Umgebung erstellen (per Anaconda [Powershell] Prompt bzw. Kommandozeile)
conda create â€“n DLfsP python=3.8
Umgebung erstellen mit Hilfe einer YAML (per Anaconda [Powershell] Prompt bzw. Kommandozeile)
Achtung, wechsle vorher in das entsprechende Verzeichnis!
conda env create -f environment.yml
Umgebung aktivieren
conda activate DLfsP
VerfÃ¼gbare Umgebungen
conda info --envs
Paket (z.B. numpy) in aktiver Umgebung installieren
conda install numpy
Umgebung deaktivieren
conda deactivate
Umgebung lÃ¶schen
conda env remove -n nutzer_projekt
AufrÃ¤umen nicht mehr gebrauchter Pakete
conda clean --all

--- Page 4 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 21
EinfÃ¼hrung Deep Learning
Installation â€“ Environment
Weitere notwendige Pakete: (per Anaconda [Powershell] Prompt bzw. Kommandozeile installieren)
conda install numpy
conda install jupyter notebook
conda install pandas
conda install scikit-learn
conda install matplotlib
conda install seaborn

--- Page 5 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 22
EinfÃ¼hrung Deep Learning
Installation â€“ TensorFlow
Keine Nvidia Grafikkarte vorhanden, dann ist nur die CPU Variante mÃ¶glich:
conda install tensorflow
GPU Variante (fÃ¼r Nvidia Grafikkarten)
Version 2.6
conda install tensorflow-gpu=2.6 tensorflow=2.6
Version 2.3
conda install tensorflow-gpu=2.3 tensorflow=2.3=mkl_py38h1fcfbd6_0
VerfÃ¼gbare Tensorflow Versionen
conda search tensorflow
VerfÃ¼gbare Tensorflow-gpu Versionen
conda search tensorflow-gpu
Achtung, im Video wurde noch
TensorFlow 2.5 installiert. Jedoch gibt
es bei dieser Version Probleme mit
RNN Netzen. Aufgrund von
InkompatibiltÃ¤ten mit numpy. Daher
wird empfohlen TensorFlow 2.6 oder
neuer zu installieren!

--- Page 6 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 23
EinfÃ¼hrung Deep Learning
Installation â€“ TensorFlow
Test, ob Python und Tensorflow richtig installiert wurde (Anaconda [Powershell] Prompt bzw. Kommandozeile):
python -c "import tensorflow as tf; print('TF version: ' + tf.__version__); print('Default GPU Device:
{}'.format(tf.config.list_physical_devices('GPU')))"
In einem Jupyter Notebook:
import tensorflow as tf
import sys
print('Python version: ' + sys.version)
print('TF version: ' + tf.__version__)
if tf.test.is_built_with_gpu_support():
if len(tf.config.list_physical_devices('GPU'))==0:
print('Please install GPU version of TF\n' + 'TF is currently using the CPU')
else:
print('Default GPU Device: {}'.format(tf.config.list_physical_devices('GPU')))
else:
print('TF CPU version active')

--- PDF: tud2022_DLfsP_M1_6_Tensor.pdf ---
--- Page 1 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 24
EinfÃ¼hrung Deep Learning
Programm
â€¢ Definition
â€¢ Wiederholung neuronale Netze
â€¢ Frameworks
â€¢ Installation
â€¢ Tensor

--- Page 2 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 25
EinfÃ¼hrung Deep Learning
Tensor
Im Bereich der KI, ML und DL wird ein Tensor als ein mehrdimensionales Array definiert.
Beispiele:
Skalar (0D Tensor)
Vektor (1D Tensor)
Matrix (2D Tensor)
3D Tensor
Beispiel: Serie von Matrizen, Farbbild
4D Tensor
Beispiel: Serie von Bildern, Video
5D Tensor
Beispiel: Serie von Videos
1,5
(1, 4, 9, 16, 25)

--- Page 3 ---

Deep Learning fÃ¼r sequentielle Prozessdaten
EinfÃ¼hrung Deep Learning
TU Dresden
Institut fÃ¼r Mechatronischen Maschinenbau
Folie 26
EinfÃ¼hrung Deep Learning
Tensor
Umsetzung von Tensoren in Python allgemein:
Numpy Arrays
fÃ¼r die meisten ML Frameworks (sklearn & co) geeignet
mutable (verÃ¤nderbar)
TensorFlow Tensoren
fÃ¼r TensorFlow
immutable (nicht verÃ¤nderbar)

================================================================================
METADATA
================================================================================

{
  "course_id": 191,
  "module_id": 22060,
  "fullname": "Folien",
  "type": "module",
  "url": "https://moodle.ki-campus.org/mod/resource/view.php?id=22060"
}