================================================================================
DOCUMENT TEXT
================================================================================

Module Name: Einführung

--- Spalten-Inhalte ---
[Video] Transkript:  Es gibt Tausende und eine Möglichkeiten, KI einzusetzen. Und dennoch gibt es auch ganz verschiedene Facetten und Nuancen, wie durch den Einsatz von KI negative Konsequenzen entstehen können. Um damit umzugehen, es diesen risikobasierten Ansatz. Den gibt es nicht nur für KI, den gibt es auch in vielen anderen Regelwerken. Es ist auch ein wiederkehrendes Konzept im Sinne der europäischen Gesetzgebung. Der Gesetzgeber entwickelt Gesetze nach einem Proportionalitätsprinzip. Das heißt, man entwickelt die Regeln, dass sie proportional sind zu dem Risiko, das mit einer gewissen Technologie oder einem Produkt einhergeht. Und vereinfacht gesagt ist die Formel so, je höher das Risiko, desto strenger die Regeln, je niedriger das Risiko, desto entspannter oder leichter sind die Regeln. Das ist auch so ein fast schon linearer Zusammenhang hier. Also schauen wir uns diese vier Klassen mal genauer an. Gerichtsmittel mit einem inakzeptablen Risiko sind wie gesagt verboten. Das sind Systeme oder Praktiken, bei denen die EU sagt, die sind im Gegensatz zu bestimmten und ganz fundamentalen Werten der EU. Beispiele sind etwa das sogenannte Predictive Policing. diese vorausschauende Polizeiarbeit, wenn man sich fragen würde, wer würde morgen eine Straftat begehen, kann ich diese Person denn schon heute ins Gefängnis stecken? Als zweites haben wir KI-Systeme mit einem hohen Risiko. Also sogenannte Hochrisiko-KI-Systeme. Das sind Anwendungen die sind prinzipiell erlaubt, aber nur wenn sie nachweislich ein recht umfangreiches Set an Regeln einhalten. Hier gibt es zwei große Buckets, zwei große Bereiche, man sagen. Einerseits Produkte, die schon auch ohne KI ein gewisses Risikopotenzial haben. Denken wir beispielsweise an Aufzüge, Spielzeuge, Medizinprodukte, Maschinen oder Fahrzeuge. Bei denen kann schon durchaus etwas schiefgehen, auch ohne KI. Auf der anderen Seite gibt es eine Reihe von Anwendungsfeldern im Bereich der man könnte sagen, Gesellschaft. Denken wir an KI in der Bildung, KI in der Strafverfolgung, in der kritischen Infrastruktur oder am Arbeitsplatz. Auch hier gibt es bestimmte Szenarien, die ein hohes Risiko aufweisen. Und auch hier gibt es dann umfassende Regeln, einzuhalten sind, wenn man KI einsetzen möchte. Als drittes haben wir den Bereich der sogenannten begrenzten Risiken. Dieser Begriff kommt so exakt nicht im Ereignis vor, aber es handelt sich dabei um sogenannte Transparenzanforderungen. D.h., man muss Transparenz aufzeigen, dass es sich um KI handelt, weil es sind Fälle, eine Verwechslungsgefahr besteht. Denken wir beispielsweise an Chatbots auf Webseiten, wo man denken könnte, man unterhält sich mit einem Menschen, aber in Wirklichkeit ist es ein KI-System. Und dann haben wir noch den Boden der Pyramide. Dabei handelt es sich um KI-Systeme mit einem geringen oder keinem Risiko. Das sind quasi alle die nicht in eine der oberen drei Stufen fallen. Beispiele dafür sind etwa in der Produktion. Denken Predictive Maintenance, also vorausschauende Wartung. Oder denken wir vielleicht an Qualitätssicherung. Vielleicht habe ich eine Großbäckerei und möchte schauen, ob der Käse auf meiner Käse-Stange die ausreichende Bräune hat. Das wäre ein KI-System, eines mit einem Niedrigrisiko, weil die negativen Konsequenzen falls es schiefgeht, die sind relativ Überschaubar. Am Anfang ist es ganz wichtig, dass man sich gut überlegt, über welches System man überhaupt spricht. Häufig sehen wir, dass wir Organisationen eine ganze Reihe an KI-Anwendungen haben oder andere IT-Systeme. Dann muss man den Verwendungszweck von diesem System festhalten. Das ist ganz wichtig, dass man hier eine präzise Formulierung hat. Dann, idealerweise, sucht man sich ein, zwei Kolleginnen, mit denen man das gemeinsam durchführen kann. Bestensfalls hat man ein diverses Team, also jemanden, der sich von der rechtlichen Seite mit dem E-Alk beschäftigt hat. Jemand, technisch versteht, wie dieses System funktioniert. Aber auch vielleicht jemanden aus der Anwendung der täglich nachher mit diesem System arbeitet. Dann arbeitet man sich diese Pyramide von oben nach unten. Das heißt, es ist ein KI-System mit einem inakzeptablen Risiko, eines mit hohem Risiko, begrenztem oder niedrigem. Man geht von oben nach unten, hier gibt es immer einstiegige Artikel. Danach kann man entscheiden, ob man in eine Klasse fällt oder in eine andere
[Text] Stell dir vor, du befindest dich in einer belebten Notaufnahme, wo ein KI-System dem Krankenhauspersonal dabei hilft, Patient*innen für die Behandlung zu priorisieren. Die Entscheidungen, die getroffen werden, sind auch ohne KI-Systeme in den Prozessen herausfordernd. Wenn nun ein KI-System in diesen Prozessen Vorschläge macht, muss es vertrauenswürdig sein. In einem anderen Teil der Stadt benutzt eine Bäckerei auf ihrer Webseite einen KI-gesteuerten Chatbot, um Kundenbestellungen entgegenzunehmen. In beiden Fällen wird KI eingesetzt, aber das Risiko in Bezug auf die Gesundheit, Sicherheit und die grundlegenden Menschenrechte, dass sie mit sich bringen, ist natürlich sehr unterschiedlich. Hier setzt der EU AI Act an und reguliert KI-Systeme proportional zu ihrem Risikopotential Was ist wann verboten? Welche KI-Systeme erfordern besondere Aufmerksamkeit und müssen bestimmte Anforderungen erfüllen? Welche können unter der Voraussetzung, dass Nutzer über die korrekte Nutzung aufgeklärt und unterrichtet wurden, frei eingesetzt werden? Welche KI-Systeme haben Transparenzpflichten gegenüber Nutzer*innen?
[Text] ab
[Text] Lea, ein Product Owner, hat in ihrer Rolle bei Solutions GmbH die Aufgabe, sich um die Entwicklung der Produkte zu kümmern. Darunter fallen auch jegliche KI-Anwendungen, die sie zum Weiterverkauf produzieren. Sie wird aus diesem Grund in diesem Modul viele unterschiedliche Produktideen ihres Teams betrachten - und sich dabei über die im EU AI Act definierte Compliance Journey Gedanken machen. Schau dir dazu die untenstehende Grafik der Compliance Journey an, um dir kurz Orientierung zu verschaffen. Du wirst sehen, dass wir uns in diesem Modul (Modul 2) mit dem Anfang beschäftigen werden. In den folgenden Modulen arbeiten wir uns dann in den noch ausgegrauten Bereichen weiter voran.
[Text] Schlüsselbegriffe zum Verständnis Hier findest du die kurze Erklärung einiger Schlüsselbegriffe, die in diesem Modul aufkommen werden. Mach dich gerne vor dem Eintauchen in das Modul vertraut.
[Accordion Panel 1] EU AI Act
[Text] Der AI Act (KI-Verordnung, KI-VO) etabliert weltweit erstmals umfassende Regeln, um eine vertrauenswürdige KI zu gewährleisten, die Grundrechte schützt und Risiken minimiert. Es ist ein risikobasiertes System (Modul 2), das die Verantwortlichkeiten auf Rollen (Modul 3) verteilt vorgibt.
[Accordion Panel 2] Anbieter
[Text] Ein Unternehmen (wie Solutions GmbH in unserer Geschichte), das KI-Systeme entwickelt und sie anderen zur Nutzung zur Verfügung stellt.
[Accordion Panel 3] Betreiber
[Text] Ein Unternehmen (wie Logistics GmbH in unserer Geschichte), das ein von einem Anbieter entwickeltes KI-System einsetzt.
[Accordion Panel 4] System mit Hohem Risiko
[Text] Ein KI-System, dessen Verwendungszweck nach dem EU AI Act ein erhebliches Potenzial hat, das Leben oder die Grundrechte von Menschen zu beeinflussen. Diese Systeme unterliegen strengeren Regeln. Beispielsweise wird KI, die bei der Rekrutierung oder zur Bewertung von Mitarbeitern eingesetzt wird, oft als hohes Risiko eingestuft. Das neue Engagement-Monitoring-Tool, HappyWorkers, das von Leas Team entwickelt wurde, gilt in unserer Geschichte als hohes Risiko. (Weiterführende Information: EU AI Act, Artikel 6, Anhang I & III)
[Accordion Panel 5] KI-Governance
[Text] Die Art und Weise, wie ein Unternehmen Regeln, Prozesse und Verantwortlichkeiten festlegt, um sicherzustellen, dass seine KI-Systeme ethisch und verantwortungsvoll entwickelt und eingesetzt werden, unter Einhaltung der relevanten Gesetze und Richtlinien.
[Accordion Panel 6] Compliance
[Text] Compliance (Regelkonformität) bezeichnet die Einhaltung von Gesetzen, Richtlinien und internen Vorschriften durch eine Organisation oder Einzelperson. Es ist ein umfassender Prozess, der darauf abzielt, Risiken zu minimieren und sicherzustellen, dass alle Aktivitäten im Einklang mit den geltenden Bestimmungen stehen.
[Accordion Panel 7] Compliance Officer
[Text] Ein Compliance Officer ist eine Rolle in einer Organisation, die für die Überwachung und Durchsetzung der Compliance-Richtlinien verantwortlich ist. Sie stellt sicher, dass alle Mitarbeiter die relevanten Gesetze und Vorschriften kennen und einhalten. Zu den Aufgaben gehören unter anderem die Durchführung von Schulungen, die Erstellung von Berichten und die Zusammenarbeit mit Aufsichtsbehörden.
[Accordion Panel 8] Product Owner
[Text] Der/Die Product Owner ist eine Rolle in einem Unternehmen. Diese ist verantwortlich für die strategische Ausrichtung und den Erfolg eines Produkts. Sie definiert die Produktvision, priorisiert Funktionen und stellt sicher, dass das Entwicklungsteam ein Produkt liefert, das den Bedürfnissen der Nutzer entspricht und den Unternehmenszielen dient.
[Accordion Panel 9] HR Manager
[Text] Ein HR Manager ist für die Verwaltung der Personalressourcen einer Organisation zuständig. Zu den Aufgaben gehören die Rekrutierung, Einstellung, Schulung und Entwicklung von Mitarbeitern, sowie die Verwaltung von Gehaltsabrechnungen, Sozialleistungen und Arbeitsbeziehungen. Der HR Manager spielt zudem eine wichtige Rolle bei der Schaffung eines positiven Arbeitsumfelds und der Förderung der Mitarbeiterzufriedenheit.

================================================================================
METADATA
================================================================================

{
  "course_id": 313,
  "module_id": 25376,
  "fullname": "Einführung",
  "type": "module",
  "url": "https://moodle.ki-campus.org/mod/h5pactivity/view.php?id=25376"
}